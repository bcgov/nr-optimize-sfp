---
author: "Copyright: Optimization Team 2025"
date: "Report compiled on `r format(Sys.time(), '%B %d, %Y')`"
output: 
    pdf_document:
      keep_tex: false
      df_print: kable
      highlight: breezedark
      latex_engine: xelatex
      includes:
          in_header: header.tex
urlcolor: blue
linkcolor: cyan
params:
  data:
    label: "Input file:"
    value: "*.csv"
    input: text
  ministry:
    label: "Ministry Name:"
    value: AF
    input: select
    choices: [AF, BCWS, EMLI, ENV, FOR, IRR, WLRS]
  share:
    label: "Share Name to Search:"
    value: "S01234"
    input: text
  collected:
    label: "datestamp on OCIO file:"
    value: 2025-03-28
    input: text
title: |
  Enhanced SFP Report on Share `r params$share` (`r params$ministry`) 
subtitle: "Data collected on `r params$collected`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 7, fig.height = 5, fig.align = "center", dev = "cairo_pdf", fig.pos = "H", fig.path = 'figure/', out.extra = "")
library(data.table)
library(DT)
library(dbplyr)
library(dplyr)
library(forcats)
library(glue)
library(here)
library(knitr)
library(lubridate)
library(magrittr)
library(openxlsx)
library(purrr)
library(scales)
library(stringr)
library(stringi)
library(tidyverse)
library(shiny)
library(zoo)
library(kableExtra)

# set working directory
here::here()
```

```{r global, call-external-functions, include = FALSE}
# load custom functions from external scripts
source(here("scripts", glue('custom_sfp_functions.R')), local = knitr::knit_global())
```

```{r load data, include = FALSE}
# load csv and fill empty cells 
sfp_data <- read_csv((here("source", glue("{params$data}", na.strings = c(""," ","NULL")))))

# keep only the first 9 columns
sfp_data <- sfp_data[,c(1:9)]

# rename columns
colnames(sfp_data) <- c("filename", "path", "filetype","category","sizemb","lastaccessdate","modificationdate","creationdate","share")
```

```{r folder search, include = FALSE}
formatted_sfp_data <- sfp_data %>%
  mutate(share = gsub("\\", "", share, fixed = TRUE)) %>%
  filter(str_detect(share, {params$share})) %>%
  mutate(root = word(path, 1, 7, sep = "\\\\")) %>%
  mutate(sizegb = sizemb / 1000) %>% 
  mutate(sizegb = round(sizegb, 3)) %>% 
  mutate(filetype = str_extract(filename, "[^.]+$")) %>%
  mutate(filetype = tolower(filetype)) %>% 
  mutate(monthly_cost = sizegb * 2.7) %>% 
  mutate(monthly_cost = round((monthly_cost), 2)) %>% 
  mutate(obj_store_cost = sizegb * 0.07) %>% 
  mutate(object_storage_cost = round((obj_store_cost), 2)) %>% 
  mutate(lastaccessdate = convert.date(lastaccessdate)) %>% 
  mutate(modificationdate = convert.date(modificationdate)) %>% 
  mutate(creationdate = convert.date(creationdate)) %>%
  select(filename, filetype, category, root, path, sizemb, sizegb, lastaccessdate, modificationdate, creationdate, monthly_cost, obj_store_cost, object_storage_cost)
```

```{r determine file types per category, include = FALSE}
sfp_categories <- formatted_sfp_data %>% 
  group_by(category, filetype) %>% 
  select(category, filetype)

sfp_categories_filetypes <- sfp_categories %>% 
  distinct() %>% 
  arrange(category, filetype)
```

```{r, include = FALSE}
#count total number of files
count_files <- nrow(formatted_sfp_data)
count_files_formatted <- format(count_files, big.mark = ",", scientific = FALSE)
```

```{r calculate share size, include = FALSE}
calc_share_size <- formatted_sfp_data %>%  
  summarize("folder size gb" = sum(sizegb), "number of files" = n(), "monthly cost" = sum(monthly_cost), "object storage cost" = sum(object_storage_cost)) 

calc_share_size <- calc_share_size[order(-calc_share_size$"monthly cost"),]
```

```{r file count per folder, include = FALSE}
#count number of files per folder
folder_filetally <- formatted_sfp_data %>%
  group_by(path) %>% 
  summarise("number of files" = n())
```

```{r calculate share category size, include = FALSE}
share_category_size <- formatted_sfp_data %>%
  group_by(category) %>% 
  summarize("Size(GB)" = sum(sizegb), "number of files" = n(), "monthly cost" = sum(monthly_cost)) %>% 
  select(category, "number of files", "Size(GB)", "monthly cost")

share_category_size <- share_category_size[order(-share_category_size$"monthly cost"),]

share_category_size$"monthly cost" <- dollar(share_category_size$"monthly cost")
share_category_size$"number of files" <- format(share_category_size$"number of files", big.mark = ",", scientific = FALSE)
share_category_size$"Size(GB)" <- format(share_category_size$"Size(GB)", digits = 3, big.mark = ",", scientific = FALSE)

share_category_size <- share_category_size %>% 
  rename(
    Category = category,
    "File Count" = "number of files",
    "Monthly Cost" = "monthly cost"
    )

share_category_size <- kbl(share_category_size, booktabs = T) %>% kable_styling(latex_options = c("striped", "hold_position"))
```

```{r calculate folder category sizes, include = FALSE}
folder_category_size <- formatted_sfp_data %>%
  group_by(category, path) %>% 
  summarize("Size(GB)" = sum(sizegb), "number of files" = n(), "monthly cost" = sum(monthly_cost), "object storage cost" = sum(object_storage_cost)) %>% 
  select(path, category, "number of files", "Size(GB)", "monthly cost", "object storage cost")

folder_category_size <- folder_category_size[order(-folder_category_size$"monthly cost"),]
```

```{r calculate folder sizes, include = FALSE}
folder_size <- formatted_sfp_data %>%
  group_by(path) %>% 
  summarize("folder size gb" = sum(sizegb), "monthly cost" = sum(monthly_cost), "object storage cost" = sum(object_storage_cost))

folder_size <- folder_size[order(-folder_size$"monthly cost"),]
```

```{r create table with folder size, depth, and file tally, include = FALSE}
table_pathsize_tallyfiles <- inner_join(folder_size,folder_filetally, by = "path") %>% 
  select(path, "number of files", "folder size gb", "monthly cost", "object storage cost")

# Count the number of '/'s in each element of string
table_pathsize_tallyfiles$folderdepth <- str_count(table_pathsize_tallyfiles$path, "/")

# count the number of '/'s in the path parameter, subtract x from beginning of path (re: escaped backslashes)
path_depth <- stri_count_fixed("{params$share}", "/")

# subtract path parameter count from each path name's count for a folder depth that starts at the desired search folder
table_pathsize_tallyfiles$folderdepth <- (table_pathsize_tallyfiles$folderdepth - path_depth) - 5

table_pathsize_tallyfiles <- table_pathsize_tallyfiles[order(-table_pathsize_tallyfiles$"monthly cost"),] %>% 
  select(path, folderdepth, "number of files", "folder size gb", "monthly cost", "object storage cost")
```

```{r tally folders based on folder depth, include = FALSE}
table_folderdepth_tallyfolders <- table_pathsize_tallyfiles %>%
  group_by(folderdepth) %>% 
  tally(name = "folderdepth_count")

table_folderdepth_tallyfolders$"folderdepth_count" <- format(table_folderdepth_tallyfolders$"folderdepth_count", big.mark = ",", scientific = FALSE)
```

```{r folder count, echo = FALSE}
# tailor this statement to the specific share
folder_count <- unique(formatted_sfp_data$path)
folder_count <- length(folder_count)
folder_count <- format(folder_count, big.mark = ",", scientific = FALSE)
```

```{r average folder depth, echo = FALSE}
# tailor this statement to the specific path
mean_depth <- as.integer(mean(table_pathsize_tallyfiles$folderdepth))
max_depth <- as.integer(max(table_pathsize_tallyfiles$folderdepth))
```

```{r size of entire share in GB, echo = FALSE}
# tailor this statement to the specific share
share_size <- sum(table_pathsize_tallyfiles$"folder size gb")
sharesize <- format(share_size, digits = 2, big.mark = ",", scientific = FALSE)
```

```{r share cost, echo = FALSE}
# calculated at $2.70 per GB
sharecost <- sum(share_size) * 2.7
share_cost <- dollar(sharecost)
objstorecost <- sum(share_size) * 0.07
objstore_cost <- dollar(objstorecost)
annualsavings <- sum(sharecost - objstorecost) * 12
annual_savings <- dollar(annualsavings)
```

```{r find duplicate files, include = FALSE}
# find files that are duplicated in both name and size
duplicate_files <- formatted_sfp_data %>% 
  group_by(filename, sizegb) %>% 
  filter( n() > 1 )

duplicate_files_formatted <- duplicate_files %>% 
  select (filename, path, category, sizegb, monthly_cost, lastaccessdate, modificationdate, creationdate) 

duplicate_files_formatted <- duplicate_files_formatted[order(-duplicate_files_formatted$monthly_cost),]

duplicate_size <- round(sum(duplicate_files_formatted$sizegb),2) # size of all the duplicated files, including originals

#duplicate_cost <- round(sum(duplicate_files_formatted$monthly_cost),2) # cost of all the duplicated files, including originals
```

```{r duplicates cost, echo = FALSE}
# calculated at $2.70 per GB
dup_new <- duplicate_files[!duplicated(duplicate_files[ , c("filename", "sizegb")]), ]

dup_size <- round(sum(dup_new$sizegb),2)
dup_size_diff <- duplicate_size - dup_size
dup_size_formatted <- format(dup_size_diff, big.mark = ",", scientific = FALSE)

dup_cost <- dollar(dup_size_diff * 2.7)
```

```{r count the duplicate files, include = FALSE}
dup_count <- nrow(duplicate_files_formatted) # count of all the duplicated files 
dist_dup <- nrow(dup_new) # count of each original file that has a duplicate

dist_dup <- format(dist_dup, big.mark = ",", scientific = FALSE)
```

```{r find files older than 2.5 yrs, include = FALSE}
# convert the data collected text to date, subtract 5 years
date <- as.Date({params$collected}, "%Y-%m-%d")
dt_less30mo <- ymd(date) - months(30)

# files last accessed more than 2.5 years ago
files_accessed_30mo <- formatted_sfp_data %>% 
  filter(lastaccessdate < dt_less30mo) %>% 
  select(filename, path, category, sizegb, monthly_cost, lastaccessdate) 

files_accessed_30mo <- files_accessed_30mo[(order(as.Date(files_accessed_30mo$lastaccessdate))),]

la_30mo_gb <- round(sum(files_accessed_30mo$sizegb),3)
la_30mos_gb <- format(la_30mo_gb, big.mark = ",", scientific = FALSE)
la_30mo_cost <- dollar(la_30mo_gb * 2.7)
```

```{r count the aged-out files, include = FALSE}
la_count <- nrow(files_accessed_30mo)

la_30mo_count <- format(la_count, big.mark = ",", scientific = FALSE)

la_percent <- (la_count / count_files) * 100

la_percent <- format(round(la_percent, 1), nsmall = 1)
```


```{r global, call-groupshare-data, cache = TRUE, include = FALSE}
# load group share dataframe  from external scripts
source(here("scripts", glue('load_groupshare_files.R')), local = knitr::knit_global())
```

```{r grpshare, dependson = "call-groupshare-data", include = FALSE, error=TRUE}
grpshare <- filter(groupshare_df, share_name == {params$share})
  
grpshare_size <- sum(grpshare$used_gb)
gs_formatted <- format(grpshare_size, big.mark = ",", scientific = FALSE)

datasrc_diff <- grpshare_size - round(share_size, 2)

grpshare_cost <- dollar(grpshare_size * 2.7)

dup_percent <- (dup_size_diff / grpshare_size) * 100 # percentage of share that consist of duplicate files, based on size, without originals

dup_percent <- format(round(dup_percent, 1), nsmall = 1)

# create a bcgov colour palette
# bc_colours <- c("#234075", "#e3a82b", "#65799e", "#FFFFFF")

# pie chart with percentages
slices <- c(share_size, datasrc_diff)
lbls <- c('Included', 'Excluded')
pct <- round(slices / sum(slices) * 100)
lbls <- paste(lbls, pct) # add percents to labels
lbls <- paste(lbls, '%', sep='') # add % to labels
```

```{r report-coverage, dependson = "grpshare", echo = FALSE, error=TRUE}
# pie(slices,labels = lbls, col=bc_colours)
# title("Report Coverage \nSFP Share", line = -1)
```

\section{SFP Information}
The `r {params$share}` SFP share is \textbf{`r {gs_formatted}` GB}, costing the ministry **`r {grpshare_cost}`** per month. 

`r {params$share}` contains `r {count_files_formatted}` files and `r {folder_count}` folders (excluding files & folders under 1MB).

\section{Duplicate Files}
\textbf{\textit{Definition:}} \textit{same name and size as another file, located in a different folder of the share.}

Duplicate files over 1MB make up **`r {dup_percent}`%** of the `r {params$share}` share, totalling \textbf{`r {dup_size_formatted}` GB}. This represents \textbf{`r {dist_dup}` files} with at least one copy.  
  
Approximately \fontspec[Color=Red]{Verdana Bold}`r {dup_cost}` per month \fontspec[Color=Black]{Verdana}could be saved by cleaning up duplicates in `r {params$share}`.

\section{Older Files}
**`r {la_percent}`%** of files over 1MB were last accessed at least 2.5 years ago \textit{(`r {la_30mo_count}` files)}. This represents \textbf{`r {la_30mos_gb}` GB} of data at a monthly cost of \fontspec[Color=Red]{Verdana Bold}`r {la_30mo_cost}`\fontspec[Color=Black]{Verdana}.
\clearpage

\begin{center}
\section{Data Categories}
\textbf{`r {params$share}` Consumption by Data Category}
`r {share_category_size}` 
\href{https://apps.nrs.gov.bc.ca/int/confluence/download/attachments/73305882/Enhanced_Reporting_File_Categories_File_Extensions.pdf?version=1&modificationDate=1655238221000&api=v2}{List of category file types} provided by the OCIO.
\end{center}
\clearpage

\section{About our Data Sources}
The source data for this report is collected quarterly from the OCIO and \textcolor{red}{does not include any files under 1MB}. This is done by design to keep the reports manageable, as including files under 1 MB would greatly increase the report.

The amount of data being analyzed in the `r {params$share}` SFP share is\textbf{ `r {sharesize}` GB}.

The total SFP share size is obtained from a secondary source: the monthly OCIO Group Share reports. This data is for comparison purposes only. It contains the share name and size but does not go into further detail. 

We are using primary and secondary data from the same month for analysis.

\section{SFP Reduction Goals}
#### Records management and data migration to address rising storage costs

- [Fiscal Year 2025-2026 Chart of NRM SFP Consumption](http://nrmccp-metabase.apps.silver.devops.gov.bc.ca/public/dashboard/5e12786a-2692-41de-b083-5dacc8492417) 
- [Fiscal Year 2024-2025 Chart of NRM SFP Consumption](http://nrmccp-metabase.apps.silver.devops.gov.bc.ca/public/dashboard/4e59fe00-e957-4336-9106-e5aa9a645f78) 

- \raggedright To learn more about reducing SFP consumption by migrating data to Object Storage, visit the Optimization team's [Confluence page](https://apps.nrs.gov.bc.ca/int/confluence/display/OPTIMIZE/NRM+Object+Storage+Service). You can also place a request through the [Jira Service Desk](https://apps.nrs.gov.bc.ca/int/jira/servicedesk/customer/portal/1/create/701) - please read the [Service Level Agreement](https://apps.nrs.gov.bc.ca/int/confluence/display/OPTIMIZE/Object+Storage+Forms?preview=/65671335/133730673/SLA_Revision_0.6.pdf) **before** submitting a request. 

- [Contact the Optimization Team](mailto:NRIDS.Optimize@gov.bc.ca)

- Do you have questions about appropriate Records Management for your data? Visit the [Government Information Management Branch](https://www2.gov.bc.ca/gov/content/governments/services-for-government/information-management-technology/records-management) or [Contact the GIM Team](mailto:gim@gov.bc.ca)

```{r dynamic output name, include = FALSE}
# create output file name based on parameters
output_excel = paste0("SFP_Enhanced_Report_", ministry, "_", share, "_", collected, ".xlsx")
```

```{r write output to Excel file, include = FALSE}
# create workbook
excel <- createWorkbook(output_excel)

# create sheet names
firstSheet = "Folder Details"
secondSheet = "Duplicate Files"
thirdSheet = "Last Accessed 2.5+ Years"
fourthSheet = "Category Details by Folder"
fifthSheet = "Category Extensions"

# add worksheets to workbook
sheet.names(firstSheet)
sheet.names(secondSheet)
sheet.names(thirdSheet)
sheet.names(fourthSheet)
sheet.names(fifthSheet)

# assign data tables to worksheets, apply filter across all sheets
dt.worksheets(1, table_pathsize_tallyfiles)
dt.worksheets(2, duplicate_files_formatted) 
dt.worksheets(3, files_accessed_30mo) 
dt.worksheets(4, folder_category_size)
dt.worksheets(5 ,sfp_categories_filetypes)

# freeze top row of all sheets
freeze.panes(1)
freeze.panes(2)
freeze.panes(3)
freeze.panes(4)
freeze.panes(5)

# set custom column widths for all sheets
setColWidths(excel, sheet = 1, cols = c(1, 2:6), widths = c(75, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 2, cols = c(1, 2, 3:8), widths = c(50, 75, 20, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 3, cols = c(1, 2, 3:8), widths = c(50, 75, 20, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 4, cols = c(1, 2:6), widths = c(75, 20, 20, 20, 20, 20))
setColWidths(excel, sheet = 5, cols = c(1:2), widths = c(20, 20))

# set currency format on column
sty1 = createStyle(numFmt="$0.00")
addStyle(excel, sheet = 1, sty1, rows=2:(nrow(table_pathsize_tallyfiles)+1), cols=5)
addStyle(excel, sheet = 1, sty1, rows=2:(nrow(table_pathsize_tallyfiles)+1), cols=6)
addStyle(excel, sheet = 2, sty1, rows=2:(nrow(duplicate_files_formatted)+1), cols=5)
addStyle(excel, sheet = 3, sty1, rows=2:(nrow(files_accessed_30mo)+1), cols=5)
addStyle(excel, sheet = 4, sty1, rows=2:(nrow(folder_category_size)+1), cols=5)
addStyle(excel, sheet = 4, sty1, rows=2:(nrow(folder_category_size)+1), cols=6)
addStyle(excel, sheet = 5, sty1, rows=2:(nrow(sfp_categories_filetypes)+1), cols=5)

# save the workbook to file
saveWorkbook(excel, file = here("output", output_excel), overwrite = TRUE)
```